{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports e datasets\n"
      ],
      "metadata": {
        "id": "rj_idwWU8RNG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk47lR-98GWg",
        "outputId": "94d375d4-d251-4a3c-c7d0-7e0378fabbcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "# Datasets\n",
        "mnist = tf.keras.datasets.mnist\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "cifar100 = tf.keras.datasets.cifar100\n",
        "\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Dataset"
      ],
      "metadata": {
        "id": "Ld903Zvt9ukq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist_network():\n",
        "  network = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)),          # 1 camada de convolução: 32 filtros 3x3\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.Conv2D(64, kernel_size = 3, activation='relu'),                                     # 2 camada de convolução: 64 filtros 3x3\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.Dropout(0.1),                                                                       # Dropa 10% dos dados (Evitando overfitting).\n",
        "      tf.keras.layers.Conv2D(128, kernel_size = 3, activation='relu'),                                    # 3 camada de convolução: 128 filtros 3x3\n",
        "      tf.keras.layers.Dropout(0.1),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(10, activation=\"softmax\")                                                     # 1 camada de saida com 10 neuronios (1 por classe)\n",
        "  ])\n",
        "\n",
        "  network.compile(optimizer = \"rmsprop\",                                                                  # otimizador rmsprop\n",
        "                loss = \"sparse_categorical_crossentropy\",\n",
        "                metrics = ['accuracy'])                                                                   # métrica final de desempenho (nao modifique!)\n",
        "\n",
        "  return network"
      ],
      "metadata": {
        "id": "xEO0R5CK9t4u"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time = datetime.now().strftime(\"%H:%M:%S\")                                                                # Obtém o tempo no inicio do programa.\n",
        "\n",
        "network = get_mnist_network()                                                                             # Obtem a rede\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()                                                   # Carrega o dataset\n",
        "\n",
        "network.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)                            # Treina a rede\n",
        "loss, accuracy = network.evaluate(x_test, y_test)                                                         # Avalia a rede\n",
        "\n",
        "print(f\"The program was started on: {time}\")\n",
        "time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "print(f\"The program has ended on: {time}\")"
      ],
      "metadata": {
        "id": "Wz-1qOJX-GI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ea230c-852c-485a-c067-a6408c2e74b8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 5s 8ms/step - loss: 0.1824 - accuracy: 0.9440 - val_loss: 0.0689 - val_accuracy: 0.9809\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0634 - accuracy: 0.9807 - val_loss: 0.0449 - val_accuracy: 0.9876\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0479 - accuracy: 0.9861 - val_loss: 0.0589 - val_accuracy: 0.9843\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0379 - accuracy: 0.9883 - val_loss: 0.0412 - val_accuracy: 0.9898\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9905 - val_loss: 0.0423 - val_accuracy: 0.9888\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0299 - accuracy: 0.9916 - val_loss: 0.0547 - val_accuracy: 0.9888\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0264 - accuracy: 0.9925 - val_loss: 0.0440 - val_accuracy: 0.9909\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.0464 - val_accuracy: 0.9912\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0194 - accuracy: 0.9944 - val_loss: 0.0379 - val_accuracy: 0.9912\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.0417 - val_accuracy: 0.9913\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9931\n",
            "The program was started on: 21:00:44\n",
            "The program has ended on: 21:01:28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fasion MNIST Dataset\n"
      ],
      "metadata": {
        "id": "KkAmRGY7PEVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fashion_mnist_network():\n",
        "  network = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu', input_shape=(28, 28, 1)),        # 1 camada de convolução: 32 filtros 3x3\n",
        "      tf.keras.layers.Dropout(0.2),                                                                   # Dropa 20% dos dados (Evitando overfitting).\n",
        "      tf.keras.layers.BatchNormalization(),                                                           # Normaliza as entradas da camada\n",
        "      tf.keras.layers.Conv2D(64, kernel_size = 3, activation='relu'),                                 # 2 camada de convolução: 64 filtros 3x3\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Conv2D(128, kernel_size = 5, activation='relu'),                                # 3 camada de convolução: 128 filtros 5x5\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')                                                 # 1 camada de saida com 10 neuronios (1 por classe)\n",
        "  ])\n",
        "\n",
        "  network.compile(optimizer = \"rmsprop\",                                                              # otimizador rmsprop\n",
        "                loss = \"sparse_categorical_crossentropy\",\n",
        "                metrics = ['accuracy'])                                                               # métrica final de desempenho (nao modifique!)\n",
        "\n",
        "  return network"
      ],
      "metadata": {
        "id": "bZCVSu8cPI_A"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time = datetime.now().strftime(\"%H:%M:%S\")                                                            # Obtém o tempo no inicio do programa.\n",
        "\n",
        "\n",
        "network = get_fashion_mnist_network()                                                                 # Obtem a rede\n",
        "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()                                       # Carrega o dataset\n",
        "\n",
        "network.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)                        # Treina a rede\n",
        "loss, accuracy = network.evaluate(x_test, y_test)                                                     # Avalia a rede\n",
        "\n",
        "print(f\"The program was started on: {time}\")\n",
        "time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "print(f\"The program has ended on: {time}\")"
      ],
      "metadata": {
        "id": "9CDvwjdCPccO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54700043-1350-4011-d2e0-233ad41710a2"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 8s 13ms/step - loss: 0.4346 - accuracy: 0.8436 - val_loss: 0.3447 - val_accuracy: 0.8808\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.2763 - accuracy: 0.8994 - val_loss: 0.2859 - val_accuracy: 0.8971\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.2316 - accuracy: 0.9152 - val_loss: 0.3038 - val_accuracy: 0.8938\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.2003 - accuracy: 0.9263 - val_loss: 0.2393 - val_accuracy: 0.9153\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.1759 - accuracy: 0.9356 - val_loss: 0.2468 - val_accuracy: 0.9147\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.1551 - accuracy: 0.9417 - val_loss: 0.2423 - val_accuracy: 0.9164\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.1357 - accuracy: 0.9500 - val_loss: 0.2145 - val_accuracy: 0.9303\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.1221 - accuracy: 0.9546 - val_loss: 0.2302 - val_accuracy: 0.9246\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.1086 - accuracy: 0.9595 - val_loss: 0.2429 - val_accuracy: 0.9224\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.1018 - accuracy: 0.9620 - val_loss: 0.2377 - val_accuracy: 0.9259\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2465 - accuracy: 0.9248\n",
            "The program was started on: 21:41:50\n",
            "The program has ended on: 21:43:39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cifar-10 Dataset"
      ],
      "metadata": {
        "id": "s3uG9HXi5f7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cifar10_network():\n",
        "  network = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu', input_shape=(32, 32, 3)),    # 1 camada de convolução: 32 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),                                                       # Normaliza as entradas da camada\n",
        "      tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu'),                             # 2 camada de convolução: 32 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dropout(0.2),                                                               # Dropa 20% dos dados (Evitando overfitting).\n",
        "      tf.keras.layers.Conv2D(64, kernel_size = 3, activation='relu'),                             # 3 camada de convolução: 64 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Conv2D(64, kernel_size = 3, activation='relu'),                             # 4 camada de convolução: 64 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.Dropout(0.3),\n",
        "      tf.keras.layers.Conv2D(128, kernel_size = 3, activation='relu'),                            # 5 camada de convolução: 128 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Conv2D(128, kernel_size = 3, activation='relu'),                            # 6 camada de convolução: 128 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.Dropout(0.4),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')                                             # 1 camada de saida com 10 neuronios (1 por classe)\n",
        "  ])\n",
        "\n",
        "  network.compile(optimizer= \"rmsprop\",                                                           # otimizador rmsprop\n",
        "                loss = \"categorical_crossentropy\",\n",
        "                metrics = ['accuracy'])                                                           # métrica final de desempenho (nao modifique!)\n",
        "\n",
        "  return network"
      ],
      "metadata": {
        "id": "pCiDYoJDAjQl"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time = datetime.now().strftime(\"%H:%M:%S\")                                                        # Obtém o tempo no inicio do programa.\n",
        "\n",
        "\n",
        "network = get_cifar10_network()                                                                   # Obtem a rede\n",
        "(x_train, y_train),(x_test, y_test) = cifar10.load_data()                                         # Carrega o dataset\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "network.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)                    # Treina a rede\n",
        "loss, accuracy = network.evaluate(x_test, y_test)                                                 # Avalia a rede\n",
        "\n",
        "print(f\"The program was started on: {time}\")\n",
        "time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "print(f\"The program has ended on: {time}\")"
      ],
      "metadata": {
        "id": "8t1qN0UOFXW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "610b7ac3-9c0d-43c9-d2e5-867ce719f155"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 15s 33ms/step - loss: 1.7743 - accuracy: 0.4015 - val_loss: 1.4546 - val_accuracy: 0.4852\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 1.2178 - accuracy: 0.5734 - val_loss: 1.1704 - val_accuracy: 0.6011\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.9860 - accuracy: 0.6514 - val_loss: 0.9611 - val_accuracy: 0.6592\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.8734 - accuracy: 0.6954 - val_loss: 0.9987 - val_accuracy: 0.6632\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.7926 - accuracy: 0.7238 - val_loss: 0.7939 - val_accuracy: 0.7166\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.7335 - accuracy: 0.7445 - val_loss: 0.7666 - val_accuracy: 0.7312\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.6833 - accuracy: 0.7645 - val_loss: 0.7527 - val_accuracy: 0.7375\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 0.6380 - accuracy: 0.7814 - val_loss: 0.6577 - val_accuracy: 0.7680\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.6061 - accuracy: 0.7909 - val_loss: 0.9531 - val_accuracy: 0.6997\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.5808 - accuracy: 0.8013 - val_loss: 0.6596 - val_accuracy: 0.7710\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6691 - accuracy: 0.7690\n",
            "The program was started on: 21:49:03\n",
            "The program has ended on: 21:51:31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cifar-100 Dataset"
      ],
      "metadata": {
        "id": "j0nbyERxHWEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cifar100_network():\n",
        "  network = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu', input_shape=(32, 32, 3)),          # 1 camada de convolução: 32 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),                                                             # Normaliza as entradas da camada\n",
        "      tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu'),                                   # 2 camada de convolução: 32 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dropout(0.2),                                                                     # Dropa 20% dos dados (Evitando overfitting).\n",
        "      tf.keras.layers.Conv2D(64, kernel_size = 3, activation='relu'),                                   # 3 camada de convolução: 64 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Conv2D(64, kernel_size = 3, activation='relu'),                                   # 4 camada de convolução: 64 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.Dropout(0.3),\n",
        "      tf.keras.layers.Conv2D(128, kernel_size = 3, activation='relu'),                                  # 5 camada de convolução: 128 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Conv2D(128, kernel_size = 3, activation='relu'),                                  # 6 camada de convolução: 128 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.Conv2D(128, kernel_size = 3, activation='relu'),                                  # 7 camada de convolução: 128 filtros 3x3\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dropout(0.3),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(2048, activation='relu'),                                                   # Camada com 2048 neurônios.\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(1024, activation='relu'),                                                   # Camada com 1024 neurônios.\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(512, activation='relu'),                                                    # Camada com 512 neurônios.\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(256, activation='relu'),                                                    # Camada com 256 neurônios.\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(100, activation='softmax')                                                  # 1 camada de saida com 100 neuronios (1 por classe)\n",
        "  ])\n",
        "\n",
        "  network.compile(optimizer = \"Adam\" ,\n",
        "                loss = 'categorical_crossentropy',\n",
        "                metrics = ['accuracy'])                                                                 # métrica final de desempenho (nao modifique!)\n",
        "\n",
        "  return network"
      ],
      "metadata": {
        "id": "9xvmBqiSHYxS"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time = datetime.now().strftime(\"%H:%M:%S\")                                                              # Obtém o tempo no inicio do programa.\n",
        "\n",
        "\n",
        "network = get_cifar100_network()                                                                        # Obtem a rede\n",
        "(x_train, y_train),(x_test, y_test) = cifar100.load_data()                                              # Carrega o dataset\n",
        "\n",
        "# Normalize images\n",
        "x_train = x_train.astype('float32')/255                                                                 # Deixa os valores de entrada da imagem no range de 0 a 1.\n",
        "x_test = x_test.astype('float32')/255\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "network.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)                          # Treina a rede\n",
        "loss, accuracy = network.evaluate(x_test, y_test)                                                       # Avalia a rede\n",
        "\n",
        "print(f\"The program was started on: {time}\")\n",
        "time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "print(f\"The program has ended on: {time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEwb5jrLHci1",
        "outputId": "84365bbf-8726-4505-b106-e5893828e317"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 22s 39ms/step - loss: 3.9214 - accuracy: 0.1138 - val_loss: 5.6132 - val_accuracy: 0.0257\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 11s 36ms/step - loss: 3.3002 - accuracy: 0.1992 - val_loss: 3.5668 - val_accuracy: 0.1868\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 11s 36ms/step - loss: 2.9113 - accuracy: 0.2675 - val_loss: 3.9189 - val_accuracy: 0.1878\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 2.6325 - accuracy: 0.3209 - val_loss: 2.8564 - val_accuracy: 0.3128\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 11s 36ms/step - loss: 2.4207 - accuracy: 0.3658 - val_loss: 2.5590 - val_accuracy: 0.3582\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 12s 39ms/step - loss: 2.2541 - accuracy: 0.4049 - val_loss: 2.5240 - val_accuracy: 0.3568\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 12s 39ms/step - loss: 2.1097 - accuracy: 0.4326 - val_loss: 2.3917 - val_accuracy: 0.3906\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 12s 39ms/step - loss: 1.9676 - accuracy: 0.4634 - val_loss: 2.3743 - val_accuracy: 0.4015\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 1.8519 - accuracy: 0.4886 - val_loss: 2.3792 - val_accuracy: 0.4041\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 11s 36ms/step - loss: 1.7451 - accuracy: 0.5100 - val_loss: 2.2175 - val_accuracy: 0.4347\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.2052 - accuracy: 0.4410\n",
            "The program was started on: 22:11:22\n",
            "The program has ended on: 22:13:36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "oqQzeg7ydM8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    # Tempo em segundos.\n",
        "    \"mnist\": {\"time\": 43, \"acc\": 0.9931},\n",
        "    \"fashion_mnist\": {\"time\": 109, \"acc\": 0.9248},\n",
        "    \"cifar10\": {\"time\": 92, \"acc\": 0.7690},\n",
        "    \"cifar100\": {\"time\": 134, \"acc\": 0.4410},\n",
        "}"
      ],
      "metadata": {
        "id": "yU6F0MXB-Xtq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}